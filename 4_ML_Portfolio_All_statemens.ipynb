{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from io import BufferedReader\n",
    "import import_ipynb\n",
    "#import optimization_cvxopt\n",
    "\n",
    "\n",
    "# THIS CODE NEEDS TO BE RUN BEFORE MAKING THE SQL CONNECTION\n",
    "\n",
    "pymysql.converters.encoders[np.float64] = pymysql.converters.escape_float\n",
    "pymysql.converters.conversions = pymysql.converters.encoders.copy()\n",
    "pymysql.converters.conversions.update(pymysql.converters.decoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "#from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{'':'',.6f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://nativeuser:password@localhost/automatic_portfolio_creation')\n",
    "querybs = \"SELECT * from balance_sheet\"\n",
    "\n",
    "dfbs =pd.read_sql(querybs,engine)\n",
    "# dffr.rename(columns = {'STK_TKR':'STOCK_TIKR'}, inplace = True)\n",
    "# dffr.rename(columns = {'Date_year':'DATE_YEAR'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://nativeuser:password@localhost/automatic_portfolio_creation')\n",
    "querycf = \"SELECT * from cash_flow_stmt\"\n",
    "\n",
    "dfcf =pd.read_sql(querycf,engine)\n",
    "# dffr.rename(columns = {'STK_TKR':'STOCK_TIKR'}, inplace = True)\n",
    "# dffr.rename(columns = {'Date_year':'DATE_YEAR'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://nativeuser:password@localhost/automatic_portfolio_creation')\n",
    "queryis = \"SELECT * from income_statement\"\n",
    "\n",
    "dfis =pd.read_sql(queryis,engine)\n",
    "#dfis.head()\n",
    "# dffr.rename(columns = {'STK_TKR':'STOCK_TIKR'}, inplace = True)\n",
    "# dffr.rename(columns = {'Date_year':'DATE_YEAR'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbs['DATE_YEAR'] = pd.to_datetime(dfbs['DATE_YEAR'], format='%Y-%m-%d')\n",
    "dfbs['year'] = pd.DatetimeIndex(dfbs['DATE_YEAR']).year\n",
    "dfcf['DATE_YEAR'] = pd.to_datetime(dfcf['DATE_YEAR'], format='%Y-%m-%d')\n",
    "dfcf['year'] = pd.DatetimeIndex(dfcf['DATE_YEAR']).year\n",
    "dfis['DATE_YEAR'] = pd.to_datetime(dfis['DATE_YEAR'], format='%Y-%m-%d')\n",
    "dfis['year'] = pd.DatetimeIndex(dfis['DATE_YEAR']).year\n",
    "del dfbs['index']\n",
    "del dfcf['index']\n",
    "del dfis['index']\n",
    "del dfbs['DATE_YEAR']\n",
    "del dfcf['DATE_YEAR']\n",
    "del dfis['DATE_YEAR']\n",
    "\n",
    "\n",
    "dfbs.head()\n",
    "dfbs.shape[0]\n",
    "dfcf.head()\n",
    "dfcf.shape[0]\n",
    "dfis.head()\n",
    "#dffr.info()\n",
    "dfis.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfbs.columns\n",
    "# dfcf.columns\n",
    "# dfis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floatlist = ['CASH_CASH_EQUIVALENT','SHORT_TERM_INVESTMNET', 'CASH_SHORT_TERM_INVST', 'RECEIVABLES',\n",
    "       'INVENTORIES', 'TOTAL_CURRENT_ASSETS', 'GOODWILL_INTANGIBLE_ASSETS',\n",
    "       'LONG_TERM_INVESTMENTS', 'TAX_ASSETS', 'TOTAL_NON_CURR_ASSETS',\n",
    "       'TOTAL_ASSETS', 'PAYABLES', 'SHORT_TERM_DEBT', 'TOTAL_CURR_LIABILITIES',\n",
    "       'LONG_TERM_DEBT', 'TOTAL_DEBT', 'DEFERRED_REVENUE', 'TAX_LIABILITIES',\n",
    "       'DEPOSIT_LIABILITIES', 'TOTAL_NON_CURR_LIABILITIES',\n",
    "       'TOTAL_LIABILITIES', 'OTHER_COMPREHENSIVE_INCOME',\n",
    "       'RETAINED_EARNINGS_DEFICIT', 'TOTAL_SHAREHOLDERS_EQUITY', 'INVESTMENTS',\n",
    "       'NET_DEBT', 'OTHER_ASSETS', 'OTHER_LIABILITIES']\n",
    "\n",
    "floatlist2 = ['DEPRECIATION_AMORTIZATION','STOCK_BASED_COMPENSATION', 'OPERATING_CASH_FLOW',\n",
    "       'CAPITAL_EXPENDITURE', 'ACQUISITIONS_DISPOSALS',\n",
    "       'INVESTMENT_PURCHASES_SALES', 'INVESTING_CASH_FLOW',\n",
    "       'ISSUANCE_DEBT_REPAYMENT', 'ISSUANCE_SHARES_BUYBACKS',\n",
    "       'DIVIDEND_PAYMENTS', 'FINANCING_CASH_FLOW', 'EFFECT_FOREX_CHANGES',\n",
    "       'NET_CASH_FLOW', 'FREE_CASH_FLOW', 'NET_CASH_MARKET_CAP']\n",
    "\n",
    "floatlist3 = ['REVENUE', 'REVENUE_GROWTH','COST_OF_REVENUE', 'GROSS_PROFIT', 'RND_EXPENSES', 'SGNA_EXPENSES',\n",
    "       'OPERATING_EXPENSES', 'OPERATING_INCOME', 'INTEREST_EXPENSE',\n",
    "       'EARNINGS_BEFORE_TAX', 'INCOME_TAX_EXPENSE',\n",
    "       'NET_INC_NON_CONTROLLING_INT', 'NET_INC_DISCONTINUED_OPS', 'NET_INCOME',\n",
    "       'PREFERRED_DIVIDENDS', 'NET_INCOME_COM', 'EPS', 'EPS_DILUTED',\n",
    "       'WEIGHTED_AVERAGE_SHS_OUT', 'WEIGHTED_AVERAGE_SHS_OUT_DIL',\n",
    "       'DIVIDEND_PER_SHARE', 'GROSS_MARGIN', 'EBITDA_MARGIN', 'EBIT_MARGIN',\n",
    "       'PROFIT_MARGIN', 'FCF_MARGIN', 'EBITDA', 'EBIT', 'CONSOLIDATED_INCOME',\n",
    "       'EARNINGS_BEFORE_MARGIN', 'NET_PROFIT_MARGIN']\n",
    "\n",
    "for eachcol in floatlist:\n",
    "    #print(eachcol)\n",
    "    dfbs[eachcol] = dfbs[eachcol].convert_objects(convert_numeric=True)\n",
    "for eachcol in floatlist2:\n",
    "    #print(eachcol)\n",
    "    dfcf[eachcol] = dfcf[eachcol].convert_objects(convert_numeric=True)\n",
    "for eachcol in floatlist3:\n",
    "    #print(eachcol)\n",
    "    dfis[eachcol] = dfis[eachcol].convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://nativeuser:password@localhost/automatic_portfolio_creation')\n",
    "querysp = \"SELECT STK_TKR, sector,mktCap from stock_profile\"\n",
    "\n",
    "dfsp =pd.read_sql(querysp,engine)\n",
    "dfsp.rename(columns = {'STK_TKR':'STOCK_TIKR'}, inplace = True)\n",
    "dfsp.head()\n",
    "#dfsf.rename(columns = {'Date_year':'DATE_YEAR'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffrs1 = pd.merge(dfbs,dfcf, on=['STOCK_TIKR','year'])\n",
    "dffrs2 = pd.merge(dffrs1,dfis, on=['STOCK_TIKR','year'])\n",
    "dffrs = pd.merge(dffrs2,dfsp, on=['STOCK_TIKR'])\n",
    "\n",
    "dffrs.head()\n",
    "dffrs2.shape[0]\n",
    "dffrs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://nativeuser:password@localhost/automatic_portfolio_creation')\n",
    "queryhp = \"SELECT * from hist_annual_return\"\n",
    "\n",
    "dfhp =pd.read_sql(queryhp,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas import ExcelWriter\n",
    "# writer = ExcelWriter('DailyRet.xlsx')\n",
    "# dftemp1.to_excel(writer,'Sheet1',index=False)\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "dfhp['ANNUAL_RETURN'] = (pow((dfhp.AVG_DAILY_RET)+1,365)-1)*100\n",
    "dfhp.rename(columns = {'YR_OF_DATE':'year'}, inplace = True)\n",
    "dfhp['year'] = pd.to_datetime(dfhp['year'], format='%Y')\n",
    "dfhp['year'] = pd.DatetimeIndex(dfhp['year']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhp.head()\n",
    "dfhp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# #dfhp = dfhp.drop('index',axis =1)\n",
    "# dfhpa = dftemp.copy()\n",
    "# #dfhpa['year'] = pd.DatetimeIndex(dfhpa['date_year']).year\n",
    "# #df_mean = dfhpa.groupby(['STOCK_TIKR','year'],as_index=False)['change'].mean()\n",
    "# # df_mean.rename(columns = {'change':'avg_daily_change'}, inplace = True)\n",
    "# # df_mean['avg_daily_change'] = df_mean['avg_daily_change']\n",
    "# dfhpa['ar'] = (pow((dfhpa.AVG_DAILY_RET)+1,365)-1)*100\n",
    "# #df_mean['ar1'] = df_mean.rpow(df_mean.avg_daily_change,365)\n",
    "\n",
    "# # df_change = pd.merge(dfhpa,df_mean_change,on=['STOCK_TIKR','year'])\n",
    "# # df_change.head()\n",
    "# # df1['Score_Squareroot']=df1['Score']**(1/2)\n",
    "# #dfhpa['ANNUAL_CHANGE'] = (dfhpa.change+1)\n",
    "# #mean_change\n",
    "# #dfhpa['YEAR'] = pd.to_datetime(dfhpa['date_year'], format='%Y-%m-%d')\n",
    "# # dfhpa['ANNUAL_CHANGE'] = dfhpa['change'].groupby(['STOCK_TIKR','DATE_YEAR']).mean()\n",
    "# # dfhpa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge = pd.merge(dffrs,dfhp, on=['STOCK_TIKR','year'])\n",
    "dfmerge = dfmerge.drop_duplicates(subset=['STOCK_TIKR', 'year'],keep='first')\n",
    "dfmerge.head()\n",
    "dfmerge.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge.to_csv('abcd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspret = pd.read_csv('sp-500-annual-returns.csv')\n",
    "dfspret['year'] = pd.DatetimeIndex(dfspret['date']).year\n",
    "dfspret.rename(columns = {'returns':'ANN_RET_SnP'}, inplace = True)\n",
    "del dfspret['date']\n",
    "dfspret.ANN_RET_SnP.dtype\n",
    "dfspret.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge1 = pd.merge(dfmerge,dfspret, on='year')\n",
    "#dfmerge1.to_csv('dfm.csv')\n",
    "dfmerge1['TREND'] = np.where(((dfmerge1['ANNUAL_RETURN'] > dfmerge1['ANN_RET_SnP'])&(dfmerge1['ANNUAL_RETURN']>0)) ,'Up','Down')\n",
    "dfmerge1.head()\n",
    "dfmerge1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfmerge1.drop('Working_Capital',inplace=True)\n",
    "# Delete these row indexes from dataFrame\n",
    "indexNames = dfmerge1[ dfmerge1['sector'] == 'Financial Services' ].index\n",
    "dfmerge1.drop(indexNames , inplace=True)\n",
    "#dfmerge1.to_csv('ML_data.csv')\n",
    "dfmerge1.sector = pd.Categorical(dfmerge1.sector)\n",
    "dfmerge1.sector = dfmerge1.sector.cat.codes\n",
    "#dfepsPer['POSITIVE'] = dfepsPer['POSITIVE'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge1.head()\n",
    "dfmerge1.shape\n",
    "#dfmerge1.to_csv('abc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfmerge1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge1 = dfmerge1.fillna(0) \n",
    "dfmerge1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"# printing the rows that have Nans\")\n",
    "# print(\"=======================================================================================\")\n",
    "# print(dfmerge[dfmerge.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfmerge[dfmerge['Average_Inventory'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfmerge1.isnull().sum())\n",
    "dfmerge1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge1.TREND = pd.Categorical(dfmerge1.TREND)\n",
    "dfmerge1['TREND'] = dfmerge1.TREND.cat.codes\n",
    "dfmerge1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge1['TREND'].value_counts()\n",
    "#dfmerge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfmerge1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfmerge['STOCK_TIKR'] = pd.Categorical(dfmerge.STOCK_TIKR)\n",
    "# dfmerge['STOCK_CAT'] = dfmerge.STOCK_TIKR.cat.codes\n",
    "# dfmerge.head()\n",
    "# dfmerge.to_csv('ML_Dataframe_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres = pd.read_csv('Soft_Recession.csv')\n",
    "#dfres.head()\n",
    "dfres['year'] = pd.DatetimeIndex(dfres['DATE']).year\n",
    "del dfres['DATE'] \n",
    "dfres.rename(columns = {'RECPROUSM156N':'recession_prob'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftr = pd.read_csv('treasury_rates.csv')\n",
    "#dftr.head()\n",
    "dftr['DATE'] = pd.to_datetime(dftr['DATE'], format='%m/%d/%Y')\n",
    "dftr['year'] = pd.DatetimeIndex(dftr['DATE']).year\n",
    "del dftr['DATE'] \n",
    "dftr.rename(columns = {'DGS10':'treasury_rate'}, inplace = True)\n",
    "#dftr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfres.isnull().sum())\n",
    "dfres.shape\n",
    "print(dftr.isnull().sum())\n",
    "dftr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftr.fillna(method='ffill',inplace=True)\n",
    "\n",
    "print(dfres.isnull().sum())\n",
    "dfres.shape\n",
    "print(dftr.isnull().sum())\n",
    "dftr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres = dfres.groupby(['year']).mean().reset_index()\n",
    "#dfres.head()\n",
    "dftr = dftr.groupby(['year']).mean().reset_index()\n",
    "#dftr.head()\n",
    "dftemp = pd.merge(dfres,dftr,on='year')\n",
    "dftemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge_param = pd.merge(dftemp,dfmerge1, on='year')\n",
    "dfmerge_param.head()\n",
    "dfmerge_param.shape[0]\n",
    "#dfmerge_param1.to_csv('merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#dfmerge.info()\n",
    "X = dfmerge_param.drop(['STOCK_TIKR','year','AVG_DAILY_RET', 'ANNUAL_RETURN', 'ANN_RET_SnP', 'TREND','mktCap'],axis=1) #features\n",
    "Y = dfmerge_param['TREND'] #target\n",
    "X.head()\n",
    "Y.tail()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,classification_report,confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "modelDtree = dtree.fit(X_train,Y_train)\n",
    "pred_dtree = dtree.predict(X_test)\n",
    "\n",
    "acc_decision_tree = round(dtree.score(X_train,Y_train)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = linear_model.SGDClassifier(max_iter=5, tol=None)\n",
    "modelSGD = sgd.fit(X_train, Y_train)\n",
    "pred_sgd = sgd.predict(X_test)\n",
    "\n",
    "acc_sgd = round(sgd.score(X_train,Y_train) *100,2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(classification_report(Y_test,predictions))\n",
    "# print(confusion_matrix(Y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression()\n",
    "modelLog = log.fit(X_train,Y_train)\n",
    "pred_log = log.predict(X_test)\n",
    "\n",
    "acc_log = round(log.score(X_train,Y_train)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "model_rfc = rfc.fit(X_train, Y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "acc_random_forest = round(rfc.score(X_train,Y_train)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3) \n",
    "model_knn = knn.fit(X_train, Y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussian = GaussianNB() \n",
    "model_gaussian = gaussian.fit(X_train, Y_train)\n",
    "gaussian_pred = gaussian.predict(X_test)  \n",
    "\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron(max_iter=5)\n",
    "model_perc = perceptron.fit(X_train, Y_train)\n",
    "perc_pred = perceptron.predict(X_test)\n",
    "\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_tr = StandardScaler().fit(X_train)\n",
    "X_scaledtr = scaler_tr.transform(X_train)\n",
    "\n",
    "scaler_te = StandardScaler().fit(X_test)\n",
    "X_scaledte = scaler_te.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC,LinearSVC\n",
    "\n",
    "svclassifier = LinearSVC()\n",
    "model_svc = svclassifier.fit(X_scaledtr, Y_train)\n",
    "svc_pred = svclassifier.predict(X_scaledte)\n",
    "\n",
    "acc_svc = round(svclassifier.score(X_scaledtr, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "xgbclassifier = xgb.XGBClassifier(objective ='reg:logistic', learning_rate = 0.009,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 50, random_state=1)\n",
    "model_xgb = xgbclassifier.fit(X_scaledtr,Y_train)\n",
    "xgb_pred = xgbclassifier.predict(X_scaledte)\n",
    "\n",
    "acc_xgb = round(xgbclassifier.score(X_scaledtr, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', \n",
    "              'Decision Tree','XGBooster'],\n",
    "    'Acc_Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_decision_tree,acc_xgb]})\n",
    "result_df = results.sort_values(by='Acc_Score', ascending=False)\n",
    "result_df = result_df.set_index('Acc_Score')\n",
    "result_df\n",
    "result_df.to_csv('Accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_val_score(rf, X_train, Y_train, cv=10, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xb = xgb.XGBClassifier(n_estimators=100)\n",
    "scores = cross_val_score(xb, X_train, Y_train, cv=5, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(rfc.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "importances.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "importances.plot(kind='bar',figsize=(15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# dtree.feature_importances_\n",
    "# plt.figure(figsize=(10,7))\n",
    "# plt.bar(X.columns, dtree.feature_importances_)\n",
    "# plt.xticks(rotation=90,fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest = RandomForestClassifier(n_estimators=100, oob_score = True)\n",
    "# random_forest.fit(X_train, Y_train)\n",
    "# random_forest_pred = random_forest.predict(X_test)\n",
    "\n",
    "# random_forest.score(X_train, Y_train)\n",
    "\n",
    "# acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "# print(round(acc_random_forest,2,), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"oob score:\", round(random_forest.oob_score_, 4)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10, 25, 50, 70], \"min_samples_split\" : [2, 4, 10, 12, 16, 18, 25, 35], \"n_estimators\": [100, 400, 700, 1000, 1500]}\n",
    "# from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "# rf = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n",
    "# clf = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1)\n",
    "# clf.fit(X_train, Y_train)\n",
    "# clf.bestparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(criterion = \"gini\", \n",
    "                                       min_samples_leaf = 1, \n",
    "                                       min_samples_split = 10,   \n",
    "                                       n_estimators=100, \n",
    "                                       max_features='auto', \n",
    "                                       oob_score=True, \n",
    "                                       random_state=1, \n",
    "                                       n_jobs=-1)\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_prediction = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, Y_train)\n",
    "\n",
    "print(\"oob score:\", round(random_forest.oob_score_, 4)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,classification_report,confusion_matrix, accuracy_score\n",
    "\n",
    "print(accuracy_score(Y_test,Y_prediction))\n",
    "print(classification_report(Y_test,Y_prediction))\n",
    "print(confusion_matrix(Y_test,Y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclassifier = xgb.XGBClassifier(objective ='reg:logistic', learning_rate = 0.009,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 50, random_state=1)\n",
    "model_xgb = xgbclassifier.fit(X_train,Y_train)\n",
    "xgb_pred = xgbclassifier.predict(X_test)\n",
    "\n",
    "acc_xgb = round(xgbclassifier.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,classification_report,confusion_matrix, accuracy_score\n",
    "\n",
    "print(accuracy_score(Y_test,xgb_pred))\n",
    "print(classification_report(Y_test,xgb_pred))\n",
    "print(confusion_matrix(Y_test,xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the Roc curve and calculate auc value\n",
    "from sklearn import metrics\n",
    "fpr1, tpr1, thresholds1 = metrics.roc_curve(Y_train, random_forest.predict_proba(X_train)[:,1])\n",
    "metrics.auc(fpr1, tpr1)\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(fpr1, tpr1, label='train')\n",
    "fpr2, tpr2, thresholds2 = metrics.roc_curve(Y_test, random_forest.predict_proba(X_test)[:,1])\n",
    "metrics.auc(fpr2, tpr2) \n",
    "plt.plot(fpr2, tpr2, label='test', c='r')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# getting the probabilities of our predictions\n",
    "y_scores = random_forest.predict_proba(X_train)\n",
    "y_scores = y_scores[:,1]\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(Y_train, y_scores)\n",
    "def plot_precision_and_recall(precision, recall, threshold):\n",
    "    plt.plot(threshold, precision[:-1], \"r-\", label=\"precision\", linewidth=5)\n",
    "    plt.plot(threshold, recall[:-1], \"b\", label=\"recall\", linewidth=5)\n",
    "    plt.xlabel(\"threshold\", fontsize=19)\n",
    "    plt.legend(loc=\"upper right\", fontsize=19)\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plot_precision_and_recall(precision, recall, threshold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve\n",
    "# # compute true positive rate and false positive rate\n",
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_train, y_scores)\n",
    "# # plotting them against each other\n",
    "# def plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n",
    "#     plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n",
    "#     plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n",
    "#     plt.axis([0, 1, 0, 1])\n",
    "#     plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n",
    "#     plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n",
    "\n",
    "# plt.figure(figsize=(14, 7))\n",
    "# plot_roc_curve(false_positive_rate, true_positive_rate)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "model3=keras.Sequential()\n",
    "model3.add(keras.layers.Dense(100, input_dim=77, activation='relu',kernel_regularizer=regularizers.l2(0.1)))\n",
    "model3.add(keras.layers.Dense(50, activation='relu'))\n",
    "model3.add(keras.layers.Dense(25, activation='relu'))\n",
    "model3.add(keras.layers.Dense(12, activation='relu'))\n",
    "model3.add(keras.layers.Dense(6, activation='relu'))\n",
    "model3.add(keras.layers.Dense(3, activation='sigmoid'))\n",
    "model3.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history=model3.fit(X_scaledtr, Y_train, epochs=300, batch_size=1000, validation_data=(X_scaledte, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy and loss\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "x = X.values\n",
    "kf = KFold(5, shuffle=True,random_state=2)\n",
    "nn_y = []\n",
    "nn_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train,test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(\"Fold #\",{fold})\n",
    "    \n",
    "    x_train = X_scaledtr\n",
    "    y_train = Y_train\n",
    "    x_test = X_scaledte\n",
    "    y_test = Y_test\n",
    "    model3=keras.Sequential()\n",
    "    model3.add(keras.layers.Dense(100, input_dim=77, activation='relu',kernel_regularizer=regularizers.l2(0.1)))\n",
    "    model3.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model3.add(keras.layers.Dense(25, activation='relu'))\n",
    "    model3.add(keras.layers.Dense(12, activation='relu'))\n",
    "    model3.add(keras.layers.Dense(6, activation='relu'))\n",
    "    model3.add(keras.layers.Dense(3, activation='sigmoid'))\n",
    "    model3.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history=model3.fit(X_scaledtr, Y_train, epochs=300, batch_size=1000, validation_data=(X_scaledte, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy and loss\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction_full = random_forest.predict(X)\n",
    "\n",
    "dfmerge_param['Prediction'] = Y_prediction_full\n",
    "dfmerge_param.head()\n",
    "dfmerge_param.to_csv('Prediction_All_stmt_All_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_port_1 = dfmerge_param[['STOCK_TIKR','year','mktCap','Prediction']].copy()\n",
    "df_ml_port_1['mktCap'] = df_ml_port_1['mktCap'].convert_objects(convert_numeric=True)\n",
    "df_ml_port_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_port_up = df_ml_port_1[(df_ml_port_1['Prediction'] == 1) & (df_ml_port_1['mktCap'] > 10000000000)]\n",
    "df_ml_port_up.head()\n",
    "df_ml_port_up.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycountval = df_ml_port_up.groupby('STOCK_TIKR')['Prediction'].count()\n",
    "#mycountval\n",
    "dfcountval = pd.DataFrame(mycountval)\n",
    "dfcountval.rename(columns={'Prediction':'COUNT'}, inplace=True)\n",
    "dfcountval = dfcountval.reset_index()\n",
    "dfcountval.head()\n",
    "dfcountval ['Next_Yr_Up'] = np.where( dfcountval['COUNT'] > 5,'Yes','No')\n",
    "dfcountval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_port = dfcountval[dfcountval['Next_Yr_Up'] == 'Yes']\n",
    "df_ml_port.head()\n",
    "df_ml_port.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
